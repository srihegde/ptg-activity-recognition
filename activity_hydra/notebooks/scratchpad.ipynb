{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17edb207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the first 2 cells for importing generic paths/packages\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def import_modules(libpath):\n",
    "    path2add = os.path.normpath(os.path.abspath(os.path.join(os.path.dirname(\n",
    "        libpath), os.path.pardir)))\n",
    "    print(f'Adding path: {path2add}')\n",
    "    if (not (path2add in sys.path)):\n",
    "        sys.path.append(path2add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c35490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding path: /home/local/KHQ/sri.hegde/kitware/activity_recognition/ptg-activity-recognition/activity_hydra/src\n"
     ]
    }
   ],
   "source": [
    "# from torchvision.models.feature_extraction import create_feature_extractor\n",
    "# from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import_modules('../src/models/components')\n",
    "from datamodules.components.frame_dataset import H2OFrameDataset, ROSFrameDataset\n",
    "from models.components.unified_fcn import UnifiedFCNModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa77d0",
   "metadata": {},
   "source": [
    "# 3D Object Detection Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the datahandler/dataloader implementation\n",
    "dataset = H2OFrameDataset(\n",
    "    '../data/h2o/', '../data/h2o/label_split/pose_train.txt')\n",
    "data = dataset[2]\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13167101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions to create grid data\n",
    "\n",
    "def conf_func(dist, alpha, dth):\n",
    "    dist = np.sqrt(np.sum((dist)**2, axis=-1))\n",
    "    mask = (dist < dth)\n",
    "    conf = np.exp(alpha*(1 - dist/dth))\n",
    "    conf = mask * conf\n",
    "    mean_conf = np.mean(conf, axis=-1)\n",
    "    return mean_conf\n",
    "\n",
    "\n",
    "def corner_confidences(cp_pred_np: np.ndarray, obj_pose: np.ndarray, l_hand: np.ndarray, r_hand: np.ndarray, alpha: float = 2.0, dth=[75, 75, 7.5]):\n",
    "    cp_gt = np.stack([obj_pose, l_hand, r_hand])\n",
    "    cp_gt = cp_gt.reshape(cp_gt.shape[:-1] + (-1, 3))\n",
    "    cp_pred_np = cp_pred_np.reshape(cp_pred_np.shape[:-1] + (-1, 3))\n",
    "    dist = cp_gt - cp_pred_np[:, :, ]\n",
    "    c_uv = conf_func(dist[..., :2], alpha, dth[0])\n",
    "    z_mask = (dist[..., -1] < dth[-1])\n",
    "    c_z = np.mean(z_mask * np.abs(dist[..., -1]), axis=-1)\n",
    "    conf = 0.5*(c_uv + c_z)\n",
    "\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f11a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the working of Unified FCN\n",
    "ufcn = UnifiedFCNModule('convnext_tiny', 21, 9, 12)\n",
    "net = ufcn.net\n",
    "train_nodes, _ = get_graph_node_names(net)\n",
    "\n",
    "net = create_feature_extractor(\n",
    "    net, return_nodes={'features.7.2.block.4': 'feat_out'})\n",
    "out = net(torch.rand(1, 3, 416, 416))\n",
    "x = out['feat_out']\n",
    "out_channels = 5 * 3 * (3 * ufcn.num_cpts + 1 +\n",
    "                        ufcn.obj_classes + ufcn.verb_classes)\n",
    "lin = nn.Linear(x.shape[-1], out_channels)\n",
    "x = lin(x)\n",
    "# x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "bsize, _, h, w = x.size()\n",
    "x_reshaped = x.contiguous().view(bsize, -1, 3, 3 * ufcn.num_cpts +\n",
    "                                 1 + ufcn.obj_classes + ufcn.verb_classes)\n",
    "# print(x.shape)\n",
    "\n",
    "# vector indices (at position 2): 0 -> object, 1 -> l_hand, 2 -> r_hand\n",
    "cp_pred = torch.sigmoid(x_reshaped[:, :, :, 0:3 * ufcn.num_cpts])\n",
    "conf_pred = x_reshaped[:, :, :, 3 * ufcn.num_cpts].contiguous()\n",
    "obj_pred = torch.sigmoid(\n",
    "    x_reshaped[:, :, 0, 3 * ufcn.num_cpts+1: 3 * ufcn.num_cpts+1+ufcn.obj_classes])\n",
    "l_verb_pred = torch.sigmoid(x_reshaped[:, :, 1, 3 * ufcn.num_cpts+1 +\n",
    "                            ufcn.obj_classes: 3 * ufcn.num_cpts+1+ufcn.obj_classes+ufcn.verb_classes])\n",
    "r_verb_pred = torch.sigmoid(x_reshaped[:, :, 2, 3 * ufcn.num_cpts+1 +\n",
    "                            ufcn.obj_classes: 3 * ufcn.num_cpts+1+ufcn.obj_classes+ufcn.verb_classes])\n",
    "\n",
    "print(cp_pred.shape, conf_pred.shape, obj_pred.shape,\n",
    "      l_verb_pred.shape, r_verb_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96620180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence computation\n",
    "l_hand, r_hand, obj_label, obj_pose, verb = data['l_hand'], data[\n",
    "    'r_hand'], data['obj_label'], data['obj_pose'], data['verb']\n",
    "conf = corner_confidences(cp_pred.data.cpu().numpy(), obj_pose, l_hand, r_hand)\n",
    "# print(conf.shape)\n",
    "\n",
    "noho_scale = 0.1\n",
    "ho_scale = 5\n",
    "conf_mask = np.ones_like(conf)*noho_scale\n",
    "print(conf_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063c301",
   "metadata": {},
   "source": [
    "# Visualize predicted and GT bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca692068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "gt = [{'gt_num': 1, 'gt_boxes_upright_depth': [[0.0608, 0.0426, 0.5437, 0.1157, 0.1120, 0.1126]], 'class': [8]}, {'gt_num': 1, 'gt_boxes_upright_depth': [[0.0367, 0.0234, 0.5902, 0.1157, 0.1120, 0.1126]], 'class': [8]}, {'gt_num': 1, 'gt_boxes_upright_depth': [[0.0276, 0.0230, 0.6005, 0.1157, 0.1120, 0.1126]], 'class': [8]}, {'gt_num': 1, 'gt_boxes_upright_depth': [[0.0098, 0.0136, 0.5946, 0.1157, 0.1120, 0.1126]], 'class': [8]}, {'gt_num': 1, 'gt_boxes_upright_depth': [[0.0230, 0.0301, 0.6039, 0.1157, 0.1120, 0.1126]], 'class': [8]}]\n",
    "results = [{'boxes_3d': [[ 4.2602e-03,  5.2471e-04,  4.9059e-02,  4.1665e-02,  6.8070e-02,\n",
    "          3.5510e-02,  6.3585e+00],\n",
    "        [ 2.7554e-03, -3.2314e-04,  3.0911e-02,  2.0331e-02,  4.1466e-02,\n",
    "          1.7244e-02,  6.3778e+00],\n",
    "        [ 1.4760e-03,  2.7081e-04,  2.2068e-02,  1.7085e-02,  3.7264e-02,\n",
    "          1.5370e-02,  6.4259e+00],\n",
    "        [ 2.5878e-03,  2.4019e-04,  3.7491e-02,  3.5269e-02,  6.2041e-02,\n",
    "          2.9389e-02,  6.4114e+00],\n",
    "        [ 1.8443e-03, -5.7145e-04,  3.1550e-02,  1.2864e-02,  3.4855e-02,\n",
    "          1.2427e-02,  6.4068e+00],\n",
    "        [ 4.8076e-03,  1.5290e-03,  4.0302e-02,  3.0070e-02,  5.4107e-02,\n",
    "          2.4297e-02,  6.3619e+00],\n",
    "        [ 1.2358e-02,  2.9496e-03,  6.4462e-02,  5.6419e-02,  8.6110e-02,\n",
    "          4.8433e-02,  6.4080e+00],\n",
    "        [ 5.3392e-03, -9.3258e-04,  4.8271e-02,  2.3491e-02,  4.8560e-02,\n",
    "          2.0297e-02,  6.3691e+00],\n",
    "        [-1.4695e-03,  6.3801e-04,  2.7495e-02,  2.1895e-02,  4.6697e-02,\n",
    "          2.0390e-02,  6.3689e+00],\n",
    "        [-3.0802e-03,  2.0738e-03,  3.9001e-02,  4.4559e-02,  7.7915e-02,\n",
    "          3.7976e-02,  6.3573e+00],\n",
    "        [-2.4542e-03, -1.1351e-03,  4.2858e-02,  1.8496e-02,  4.5568e-02,\n",
    "          1.8163e-02,  6.3802e+00],\n",
    "        [ 9.9102e-03,  2.5398e-02,  9.2619e-02,  9.9285e-02,  1.4596e-01,\n",
    "          9.9848e-02,  6.3094e+00]], 'scores_3d': [0.2975, 0.2823, 0.2410, 0.2406, 0.1858, 0.1828, 0.1757, 0.1128, 0.1045,\n",
    "        0.0875, 0.0748, 0.0644], 'labels_3d': [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]}, {'boxes_3d': [[ 3.5143e-03,  1.1140e-03,  4.5588e-02,  4.4120e-02,  7.2670e-02,\n",
    "          3.8275e-02,  6.3660e+00],\n",
    "        [ 2.2898e-03, -3.3071e-04,  2.5120e-02,  2.2491e-02,  4.4327e-02,\n",
    "          1.8669e-02,  6.3837e+00],\n",
    "        [ 2.4653e-03,  6.7453e-04,  3.4972e-02,  3.6590e-02,  6.1495e-02,\n",
    "          3.0332e-02,  6.4175e+00],\n",
    "        [ 1.2567e-03,  2.1678e-04,  2.1562e-02,  1.6043e-02,  3.5033e-02,\n",
    "          1.3773e-02,  6.4222e+00],\n",
    "        [ 1.3964e-03,  6.7389e-05,  3.0861e-02,  1.2121e-02,  3.3254e-02,\n",
    "          1.1411e-02,  6.4274e+00],\n",
    "        [-1.5366e-03,  6.7237e-04,  2.6178e-02,  2.0999e-02,  4.5943e-02,\n",
    "          1.9971e-02,  6.3779e+00],\n",
    "        [ 6.3550e-03,  1.2876e-03,  3.6886e-02,  3.2408e-02,  5.7179e-02,\n",
    "          2.7509e-02,  6.4173e+00],\n",
    "        [ 1.4005e-02,  4.3267e-03,  6.6092e-02,  5.8352e-02,  8.8441e-02,\n",
    "          4.9612e-02,  6.4718e+00],\n",
    "        [-2.4569e-03,  1.6528e-03,  4.0393e-02,  4.2257e-02,  7.3554e-02,\n",
    "          3.5196e-02,  6.3795e+00],\n",
    "        [ 7.5612e-03, -1.5335e-03,  5.1426e-02,  2.4108e-02,  5.0948e-02,\n",
    "          2.1128e-02,  6.4236e+00],\n",
    "        [ 9.2552e-03,  2.7353e-02,  9.4263e-02,  1.0368e-01,  1.5013e-01,\n",
    "          9.8138e-02,  6.3014e+00]], 'scores_3d': [0.2935, 0.2829, 0.2604, 0.2549, 0.1933, 0.1420, 0.1240, 0.1172, 0.1156,\n",
    "        0.0876, 0.0665], 'labels_3d': [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]}, {'boxes_3d': [[ 2.2215e-03,  1.2342e-03,  4.5963e-02,  4.5802e-02,  7.3616e-02,\n",
    "          3.8791e-02,  6.3598e+00],\n",
    "        [ 1.5422e-03,  1.9453e-04,  2.8852e-02,  2.2254e-02,  4.3009e-02,\n",
    "          1.7833e-02,  6.3638e+00],\n",
    "        [ 1.7672e-03,  2.2735e-04,  3.6136e-02,  3.7316e-02,  6.3868e-02,\n",
    "          3.1232e-02,  6.4154e+00],\n",
    "        [ 8.3405e-04,  1.8281e-04,  2.1335e-02,  1.7564e-02,  3.7569e-02,\n",
    "          1.5221e-02,  6.4088e+00],\n",
    "        [ 7.8722e-04,  3.1088e-04,  3.0859e-02,  1.2647e-02,  3.4672e-02,\n",
    "          1.2047e-02,  6.4058e+00],\n",
    "        [-1.8676e-03,  5.3797e-04,  2.4578e-02,  2.0148e-02,  4.3895e-02,\n",
    "          1.9182e-02,  6.3849e+00],\n",
    "        [-3.0614e-03,  1.5974e-03,  3.7432e-02,  4.2867e-02,  7.4040e-02,\n",
    "          3.6636e-02,  6.3648e+00],\n",
    "        [ 6.1169e-03,  2.0373e-03,  4.1623e-02,  3.1713e-02,  5.5458e-02,\n",
    "          2.6231e-02,  6.4310e+00],\n",
    "        [ 1.4327e-02,  4.4097e-03,  7.1036e-02,  6.0509e-02,  8.9436e-02,\n",
    "          5.1614e-02,  6.4688e+00],\n",
    "        [ 7.6242e-03, -1.4671e-03,  5.1131e-02,  2.4165e-02,  5.0639e-02,\n",
    "          2.1695e-02,  6.4447e+00],\n",
    "        [ 6.9473e-03,  2.8553e-02,  1.0006e-01,  1.0847e-01,  1.5243e-01,\n",
    "          1.0024e-01,  6.2842e+00]], 'scores_3d': [0.2967, 0.2812, 0.2659, 0.2577, 0.1947, 0.1489, 0.1246, 0.1203, 0.1050,\n",
    "        0.0831, 0.0618], 'labels_3d': [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]}, {'boxes_3d': [[ 2.0585e-03, -3.7776e-04,  2.9671e-02,  2.2234e-02,  4.3007e-02,\n",
    "          1.7865e-02,  6.4333e+00],\n",
    "        [ 3.7915e-03,  7.6625e-04,  4.8518e-02,  4.4233e-02,  7.3481e-02,\n",
    "          3.7787e-02,  6.4017e+00],\n",
    "        [ 2.1777e-03,  2.7639e-04,  3.5109e-02,  3.7682e-02,  6.4989e-02,\n",
    "          3.1578e-02,  6.4383e+00],\n",
    "        [ 1.3203e-03, -1.8006e-04,  2.1038e-02,  1.6179e-02,  3.5543e-02,\n",
    "          1.4186e-02,  6.4761e+00],\n",
    "        [ 1.1089e-03, -4.8889e-04,  3.0157e-02,  1.2362e-02,  3.4118e-02,\n",
    "          1.1559e-02,  6.4289e+00],\n",
    "        [-1.1203e-03,  1.4172e-04,  2.3592e-02,  1.9768e-02,  4.4702e-02,\n",
    "          1.9158e-02,  6.4054e+00],\n",
    "        [ 6.6975e-03,  9.2305e-04,  3.9167e-02,  3.2537e-02,  5.7294e-02,\n",
    "          2.6770e-02,  6.4495e+00],\n",
    "        [-2.8697e-03,  1.5351e-03,  3.8210e-02,  4.4426e-02,  7.5343e-02,\n",
    "          3.7498e-02,  6.4079e+00],\n",
    "        [-1.3871e-03, -1.2734e-03,  3.8744e-02,  1.6143e-02,  4.1936e-02,\n",
    "          1.6370e-02,  6.4024e+00],\n",
    "        [ 1.5768e-02,  4.9125e-03,  7.1725e-02,  6.4920e-02,  9.5957e-02,\n",
    "          5.5656e-02,  6.4698e+00],\n",
    "        [ 7.2098e-03, -9.0235e-04,  4.8401e-02,  2.3512e-02,  4.8862e-02,\n",
    "          2.0625e-02,  6.4217e+00],\n",
    "        [ 9.3729e-03,  3.0865e-02,  1.0556e-01,  1.0813e-01,  1.5269e-01,\n",
    "          1.0352e-01,  6.3016e+00]], 'scores_3d': [0.2836, 0.2812, 0.2607, 0.2582, 0.1879, 0.1539, 0.1176, 0.1167, 0.1031,\n",
    "        0.1023, 0.0912, 0.0576], 'labels_3d': [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]}, {'boxes_3d': [[ 2.3924e-03,  1.0150e-03,  4.5687e-02,  4.5438e-02,  7.3256e-02,\n",
    "          3.8520e-02,  6.3666e+00],\n",
    "        [ 1.5279e-03,  6.0028e-04,  2.7723e-02,  2.2595e-02,  4.4020e-02,\n",
    "          1.8334e-02,  6.3806e+00],\n",
    "        [ 1.4771e-03,  1.4006e-05,  3.5330e-02,  3.5814e-02,  6.1235e-02,\n",
    "          2.9381e-02,  6.4096e+00],\n",
    "        [ 6.3927e-04,  3.8336e-04,  2.0594e-02,  1.6960e-02,  3.6159e-02,\n",
    "          1.4450e-02,  6.4069e+00],\n",
    "        [ 4.2850e-04,  5.8526e-04,  2.9921e-02,  1.2704e-02,  3.5004e-02,\n",
    "          1.2056e-02,  6.3828e+00],\n",
    "        [-2.0349e-03,  5.9369e-04,  2.3466e-02,  1.9317e-02,  4.2250e-02,\n",
    "          1.8173e-02,  6.3765e+00],\n",
    "        [-3.0615e-03,  1.4443e-03,  3.4656e-02,  4.2257e-02,  7.3143e-02,\n",
    "          3.5784e-02,  6.3724e+00],\n",
    "        [ 6.5856e-03,  2.2203e-03,  4.2721e-02,  3.2581e-02,  5.6871e-02,\n",
    "          2.6687e-02,  6.4282e+00],\n",
    "        [ 1.4278e-02,  4.6393e-03,  7.1333e-02,  6.3113e-02,  9.1646e-02,\n",
    "          5.4669e-02,  6.4552e+00],\n",
    "        [ 8.4494e-03, -1.5283e-03,  5.5426e-02,  2.5070e-02,  5.2540e-02,\n",
    "          2.2768e-02,  6.4366e+00],\n",
    "        [ 7.5856e-03,  2.7500e-02,  9.6643e-02,  1.0626e-01,  1.5090e-01,\n",
    "          9.9937e-02,  6.2948e+00]], 'scores_3d': [0.2976, 0.2846, 0.2724, 0.2543, 0.1893, 0.1558, 0.1299, 0.1096, 0.1009,\n",
    "        0.0812, 0.0598], 'labels_3d': [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fa51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuboid_data(center, size):\n",
    "    '''\n",
    "    Create a data array for cuboid plotting.\n",
    "\n",
    "\n",
    "    ============= ================================================\n",
    "    Argument      Description\n",
    "    ============= ================================================\n",
    "    center        center of the cuboid, triple\n",
    "    size          size of the cuboid, triple, (x_length,y_width,z_height)\n",
    "    :type size: tuple, numpy.array, list\n",
    "    :param size: size of the cuboid, triple, (x_length,y_width,z_height)\n",
    "    :type center: tuple, numpy.array, list\n",
    "    :param center: center of the cuboid, triple, (x,y,z)\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    # suppose axis direction: x: to left; y: to inside; z: to upper\n",
    "    # get the (left, outside, bottom) point\n",
    "    o = [a - b / 2 for a, b in zip(center, size)]\n",
    "    # get the length, width, and height\n",
    "    l, w, h = size\n",
    "    x = np.array([[o[0], o[0] + l, o[0] + l, o[0], o[0]],  # x coordinate of points in bottom surface\n",
    "         [o[0], o[0] + l, o[0] + l, o[0], o[0]],  # x coordinate of points in upper surface\n",
    "         [o[0], o[0] + l, o[0] + l, o[0], o[0]],  # x coordinate of points in outside surface\n",
    "         [o[0], o[0] + l, o[0] + l, o[0], o[0]]])  # x coordinate of points in inside surface\n",
    "    y = np.array([[o[1], o[1], o[1] + w, o[1] + w, o[1]],  # y coordinate of points in bottom surface\n",
    "         [o[1], o[1], o[1] + w, o[1] + w, o[1]],  # y coordinate of points in upper surface\n",
    "         [o[1], o[1], o[1], o[1], o[1]],          # y coordinate of points in outside surface\n",
    "         [o[1] + w, o[1] + w, o[1] + w, o[1] + w, o[1] + w]])    # y coordinate of points in inside surface\n",
    "    z = np.array([[o[2], o[2], o[2], o[2], o[2]],                        # z coordinate of points in bottom surface\n",
    "         [o[2] + h, o[2] + h, o[2] + h, o[2] + h, o[2] + h],    # z coordinate of points in upper surface\n",
    "         [o[2], o[2], o[2] + h, o[2] + h, o[2]],                # z coordinate of points in outside surface\n",
    "         [o[2], o[2], o[2] + h, o[2] + h, o[2]]])                # z coordinate of points in inside surface\n",
    "    return x, y, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae274db",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(gt)\n",
    "for i in range(N):\n",
    "    gt_box = np.array(gt[i]['gt_boxes_upright_depth'])\n",
    "    pred_box = np.array(results[i]['boxes_3d'])[:,:6]\n",
    "    \n",
    "    all_boxes = np.concatenate([gt_box, pred_box])\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    for b in range(len(all_boxes)):\n",
    "        X, Y, Z = cuboid_data(all_boxes[b][:3], (all_boxes[b][3], all_boxes[b][4], all_boxes[b][5]))\n",
    "        if b == 0:\n",
    "            col = 'r'\n",
    "        else:\n",
    "            col = 'b'\n",
    "        ax.plot_surface(X, Y, Z, color=col, rstride=1, cstride=1, alpha=0.1)\n",
    "#     ax.set_xlabel('X')\n",
    "#     ax.set_xlim(-100, 100)\n",
    "#     ax.set_ylabel('Y')\n",
    "#     ax.set_ylim(-100, 100)\n",
    "#     ax.set_zlabel('Z')\n",
    "#     ax.set_zlim(-100, 100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8eabb5",
   "metadata": {},
   "source": [
    "# Pre-computation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed2cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnext50_32x4d\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d34ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UnifiedFCNModule(\"resnext\", 21, 9, 12).to('cuda')\n",
    "trans = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ]\n",
    "            )\n",
    "root_path = \"../data/rosdata/\"\n",
    "dataset = ROSFrameDataset(root_path, '../data/rosdata/label_split/frames.txt', trans)\n",
    "dataloader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=1,\n",
    "            num_workers=12,\n",
    "            pin_memory=False,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "print(len(dataloader))\n",
    "for data in tqdm.tqdm(dataloader):\n",
    "    data[\"frm\"] = data[\"frm\"].to('cuda')\n",
    "#     data[\"obj_label\"] = data[\"obj_label\"].to('cuda')\n",
    "#     data[\"verb\"] = data[\"verb\"].to('cuda')    \n",
    "    feats, _, _ = net(data)\n",
    "    labels = {k: data[k] for k in data if k != 'frm'}\n",
    "    sample_info = dict(feats=feats, labels=labels)\n",
    "\n",
    "    fsplit = data['fname'][0].strip().split('/')\n",
    "    if not os.path.isdir('/'.join(fsplit[:-2] + ['feat'])):\n",
    "        os.mkdir('/'.join(fsplit[:-2] + ['feat']))\n",
    "    fpath = '/'.join(fsplit[:-2] + ['feat', f'{fsplit[-1].split(\".\")[0]}.pk'])\n",
    "#     print(fpath)\n",
    "    torch.save(sample_info, fpath)\n",
    "\n",
    "print(\"All training image features computed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ae366",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = torch.load(fpath)\n",
    "all_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83c4ca",
   "metadata": {},
   "source": [
    "# Saving Checkpoint and Converting from Lightning to Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dad89206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this section, move the notebook to the \n",
    "# `ptg-activity-recognition/activity_hydra` folder and adjust the paths \n",
    "# in cell 2 accordingly\n",
    "\n",
    "import torch\n",
    "\n",
    "from models.unified_ho_module import UnifiedHOModule\n",
    "from models.components.rulstm import RULSTM\n",
    "from models.components.unified_fcn import UnifiedFCNModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00a1e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RULSTM(\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      "  (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
      "  (fc_h): Linear(in_features=126, out_features=128, bias=True)\n",
      "  (rolling_lstm): OpenLSTM(\n",
      "    (lstm): LSTM(256, 128, num_layers=3)\n",
      "  )\n",
      "  (unrolling_lstm): LSTM(256, 128, num_layers=3)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0, inplace=False)\n",
      "    (1): Linear(in_features=128, out_features=6, bias=True)\n",
      "  )\n",
      "  (loss): CrossEntropyLoss()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local/KHQ/sri.hegde/miniconda3/envs/myenv/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'fcn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['fcn'])`.\n",
      "  rank_zero_warn(\n",
      "/home/local/KHQ/sri.hegde/miniconda3/envs/myenv/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'temporal' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['temporal'])`.\n",
      "  rank_zero_warn(\n",
      "/home/local/KHQ/sri.hegde/miniconda3/envs/myenv/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (MaxMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure you are using the same hyperparams as config file\n",
    "snet = UnifiedFCNModule(\n",
    "    net= \"resnext\",\n",
    "    num_cpts= 21,\n",
    "    obj_classes= 9,\n",
    "    verb_classes= 12\n",
    ")\n",
    "tnet = RULSTM(\n",
    "    act_classes= 6,\n",
    "    hidden= 128,\n",
    "    dropout= 0,\n",
    "    depth= 3,\n",
    "    sequence_completion= False,\n",
    "    return_context= False\n",
    ")\n",
    "model = UnifiedHOModule(\n",
    "    fcn=snet,\n",
    "    temporal=tnet,\n",
    "    lr= 5e-3,\n",
    "    weight_decay= 0,\n",
    "    data_type= \"video\"\n",
    ")\n",
    "model.load_from_checkpoint(fcn=snet,\n",
    "    temporal=tnet,\n",
    "    lr= 5e-3,\n",
    "    weight_decay= 0,\n",
    "    data_type= \"video\",\n",
    "    checkpoint_path= '../../datasets/checkpoints/rosbag_best_3.ckpt')\n",
    "\n",
    "# Save in PyTorch format\n",
    "PATH = '../../datasets/checkpoints/rosbag_pytorch.ckpt'\n",
    "torch.save(model.temporal.state_dict(), PATH)\n",
    "print(model.temporal)\n",
    "\n",
    "# Testing loading\n",
    "new_tnet = RULSTM(\n",
    "    act_classes= 6,\n",
    "    hidden= 128,\n",
    "    dropout= 0,\n",
    "    depth= 3,\n",
    "    sequence_completion= False,\n",
    "    return_context= False\n",
    ")\n",
    "new_tnet.load_state_dict(torch.load(PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv] *",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
